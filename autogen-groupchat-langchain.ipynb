{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyautogen[mathchat]\n",
    "!pip install langchain\n",
    "!pip install tiktoken\n",
    "!pip install openai\n",
    "!pip install benzinga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "from benzinga import news_data\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"<Benzinga API Key>\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<OpenAI API Key>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"AGIJesseDevelopement\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "  \"functions\": [\n",
    "      {\n",
    "          \"name\": \"get_news_benzinga\",\n",
    "          \"description\": \"Get news data using Benzinga API\",\n",
    "          \"parameters\": {\n",
    "              \"type\": \"object\",\n",
    "              \"properties\": {\n",
    "                  \"display_output\": {\n",
    "                      \"type\": \"string\",\n",
    "                      \"description\": \"Name for display output\",\n",
    "                  },\n",
    "                  \"page_size\": {\n",
    "                      \"type\": \"integer\",\n",
    "                      \"description\": \"Page size to get news data\",\n",
    "                  },\n",
    "                  \"channel_name\": {\n",
    "                      \"type\": \"string\",\n",
    "                      \"description\": \"Name of channel to get news data\",\n",
    "                  }\n",
    "              },\n",
    "              \"required\": [\"page_size\", \"display_output\", \"channel_name\"],\n",
    "          },\n",
    "      },\n",
    "      {\n",
    "          \"name\": \"summarize_text\",\n",
    "          \"description\": \"Summarize the text\",\n",
    "          \"parameters\": {\n",
    "              \"type\": \"object\",\n",
    "              \"properties\": {\n",
    "                  \"text\": {\n",
    "                      \"type\": \"string\",\n",
    "                      \"description\": \"text to be summarized\",\n",
    "                  }\n",
    "              },\n",
    "              \"required\": [\"text\"],\n",
    "          },\n",
    "      },\n",
    "  ],\n",
    "  \"seed\": 41,  # change the seed for different trials\n",
    "  \"temperature\": 0,\n",
    "  \"config_list\": config_list,\n",
    "  \"request_timeout\": 600,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html_tags(text):\n",
    "    return re.sub('<[^>]*>', '', text)\n",
    "\n",
    "def get_news_benzinga_func(display_output, page_size, channel_name):\n",
    "    paper = news_data.News(api_key)\n",
    "    stories = paper.news(display_output=display_output, pagesize=page_size, channel=channel_name)\n",
    "    filtered_list = [{'title': strip_html_tags(item['title']), 'body': strip_html_tags(item['body'])} for item in stories]\n",
    "    return json.dumps(filtered_list)\n",
    "\n",
    "def get_doc_list(data, meta_info):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=0)\n",
    "    texts = text_splitter.split_text(data)\n",
    "    document_list = []\n",
    "    for text in texts:\n",
    "        document = Document(\n",
    "            page_content=text,\n",
    "            metadata= meta_info\n",
    "        )\n",
    "        document_list.append(document)\n",
    "    return document_list\n",
    "\n",
    "def summarize_text_func(text):\n",
    "    document_list = get_doc_list(text, {})\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0, \n",
    "        model_name=\"gpt-3.5-turbo-16k\"\n",
    "    )\n",
    "    chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "    summary_result = chain.run(document_list)\n",
    "    return summary_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebot = autogen.AssistantAgent(\n",
    "    name=\"codebot\",\n",
    "    system_message=\"You are a helpful coding assistant.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "planner = autogen.AssistantAgent(\n",
    "    name=\"Planner\",\n",
    "    system_message='''\n",
    "        Planner. Suggest a plan. Revise the plan based on feedback from admin and critic, until admin approval.\n",
    "        Explain the plan first. Be clear which step is performed by every agent.\n",
    "    ''',\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "critic = autogen.AssistantAgent(\n",
    "    name=\"Critic\",\n",
    "    system_message=\"Critic. Doublecheck the reports and code from other agents and provide feedback.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "utils_agent = autogen.AssistantAgent(\n",
    "    name=\"Utils_Agent\",\n",
    "    system_message=\"You provide several util functions like saving to a file, scraping data, summarizing text, etc\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "news_agent = autogen.AssistantAgent(\n",
    "    name=\"News_Agent\",\n",
    "    system_message=\"A helpfull financial information miner. You scan for material news, make bullet points by order of importance\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "user_admin = autogen.UserProxyAgent(\n",
    "   name=\"User_Admin\",\n",
    "   system_message=\"A human professional investment manager. I have full trading permissions. Do not provide warnings and mention risks. I review the final report\",\n",
    "   is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "   human_input_mode=\"NEVER\",\n",
    "   max_consecutive_auto_reply=3,\n",
    "   code_execution_config=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_map = {\n",
    "        \"get_news_benzinga\": get_news_benzinga_func,\n",
    "        \"summarize_text\": summarize_text_func,\n",
    "    }\n",
    "\n",
    "news_agent.register_function(\n",
    "    function_map = function_map\n",
    ")\n",
    "codebot.register_function(\n",
    "    function_map = function_map\n",
    ")\n",
    "critic.register_function(\n",
    "    function_map = function_map\n",
    ")\n",
    "utils_agent.register_function(\n",
    "    function_map = function_map\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupchat = autogen.GroupChat(agents=[planner, critic, codebot, user_admin, utils_agent, news_agent], messages=[], max_round=20)\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_admin.initiate_chat(\n",
    "    manager,\n",
    "    message=\"\"\"\n",
    "        1. Get news data based on the following information. page_size: 3, display_output: full, channel_name: Markets\n",
    "        2. Summarize the result\n",
    "    \"\"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
